version: "3.9"

services:
  flowise:
    container_name: flowise

    ## Change to your platform example linux/arm64 or linux/amd64
    platform: linux/amd64

    ## Look at docs https://github.com/FlowiseAI/Flowise
    image: flowiseai/flowise:2.2.3

    ## Port to expose on machine
    ports:
      - 3001:3001

    ## Model Volume mount <local path>:/app/backend/data
    volumes:
      - FLOWISE_DATA_PATH:/data

    ## Environment variables see docs
    environment:
      - PORT=3001
      - CORS_ORIGINS=*
      - IFRAME_ORIGINS=*
      - FLOWISE_USERNAME=test
      - FLOWISE_PASSWORD=test
      - FLOWISE_FILE_SIZE_LIMIT=500mb
      - DEBUG=false
      - DATABASE_TYPE=postgres
      - DATABASE_PORT=5432
      - DATABASE_HOST=postgres
      - DATABASE_NAME=${POSTGRES_DB}
      - DATABASE_USER=${POSTGRES_USER}
      - DATABASE_PASSWORD=${POSTGRES_PASSWORD}
      - DATABASE_SSL=false
      - DATABASE_PATH=/data
      - BLOB_STORAGE_PATH=/data/uploads
      - APIKEY_PATH=/data
      - SECRETKEY_PATH=/data
      # - DATABASE_SSL_KEY_BASE64=
      # - APIKEY_STORAGE_TYPE=
      # - FLOWISE_SECRETKEY_OVERWRITE=
      # - LOG_LEVEL=
      # - LOG_PATH=
      # - DISABLE_FLOWISE_TELEMETRY=
      # - MODEL_LIST_CONFIG_JSON=
      # - GLOBAL_AGENT_HTTP_PROXY=
      # - GLOBAL_AGENT_HTTPS_PROXY=
      # - GLOBAL_AGENT_NO_PROXY=
      # - DISABLED_NODES=

    networks:
      - localai_nvidia_ai_network

    stdin_open: true
    tty: true
    restart: unless-stopped

volumes:
  FLOWISE_DATA_PATH:
    driver: local

networks:
  localai_nvidia_ai_network:
    external: true
